---
title: "Group 2 - merge data sets"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(knitr)
library(kableExtra)
library(dplyr)
library('fastDummies')
```


### Data cleaning - building on Joachim's example

Reading insolvency data in August and September where subject is "Eröffnungen"

```{r readData}

#orbis_raw <- read.csv(
#  "../raw_data/orbis_wrds_de.csv", 
#  header = TRUE,
#  fileEncoding = "UTF-8"
#)

orbis_raw_top1000 <- read.csv(
  "../raw_data/orbis_wrds_de.csv", 
  header = TRUE,
  fileEncoding = "UTF-8",
  nrows = 100000
)


insol_raw <- read.csv(
  "../raw_data/insolvency_filings_de_julaug2020.csv",
  header = TRUE, 
  fileEncoding = "UTF-8"
)

insol_filter <- insol_raw %>%
                  select(date,insolvency_court,court_file_number,subject,name_debtor,domicile_debtor) %>%
                  filter(subject == "Eröffnungen" & date >= "2020-08-01" & date <= "2020-09-30")
```

Deleting duplicates

```{r deleteDups}
insol_de <- insol_filter %>% unique()
```

Missing values check

```{r displayNAs}
na_vals <- insol_de %>%
  summarise_all(list( ~ sum(is.na(.))))

nas_df <- tibble(
  Variable = names(insol_de),
  `NA count` = t(na_vals)
)

kable(nas_df) %>% 
  kable_styling(full_width = FALSE)
```



Merging data 
```{r datamerge}

top1000rightjoin_data <- merge(x = insol_de, y = orbis_raw_top1000, by.x = "name_debtor", by.y = "name_native", all=TRUE)

#Need to count the number of distinct matches

#Run a fuzzy join


#Define a set of informative variables and compare the insolvent firms with the others


#examples: total asset, calc profit., firm age, size, legalfrm, audit (for Joachim's sake)


```


Generate new variables
```{r newvars}
attach(top1000rightjoin_data)
top1000rightjoin_data$expe <- rowSums(top1000rightjoin_data[,c("cost", "fipl", "taxa", "exex")], na.rm = TRUE)
top1000rightjoin_data$neti <- top1000rightjoin_data$turn - top1000rightjoin_data$expe
top1000rightjoin_data$roa <- top1000rightjoin_data$neti / top1000rightjoin_data$toas
top1000rightjoin_data$astu <- top1000rightjoin_data$opre / top1000rightjoin_data$toas
detach(top1000rightjoin_data)
```


Data analysis
```{r datanalysis}

top1000rightjoin_data <- dummy_cols(top1000rightjoin_data, select_columns = 'subject')
top1000rightjoin_data$subject_Eröffnungen[is.na(top1000rightjoin_data$subject_Eröffnungen)] <- 0
top1000rightjoin_data$subject_NA[is.na(top1000rightjoin_data$subject_NA)] <- 0



top1000rightjoin_data %>%
  group_by(subject, legalfrm) %>%
  summarise(N = n(), .groups = "drop")

```


Data analysis
```{r datanalysis}

top1000rightjoin_data <- dummy_cols(top1000rightjoin_data, select_columns = 'subject')
top1000rightjoin_data$subject_Eröffnungen[is.na(top1000rightjoin_data$subject_Eröffnungen)] <- 0
top1000rightjoin_data$subject_NA[is.na(top1000rightjoin_data$subject_NA)] <- 0


top1000rightjoin_data %>%
  group_by(subject, major_sector) %>%
  summarise(N = n(), .groups = "drop")

```


Numerical data analysis
```{r numdataanalysis}

top1000rightjoin_data %>%
  group_by(subject) %>%
  summarise(meantoas = mean(toas, na.rm = TRUE),
            meanempl = mean(empl, na.rm = TRUE),
            meanroa = mean(roa, na.rm = TRUE),
            meanastu = mean(astu, na.rm = TRUE))

```


